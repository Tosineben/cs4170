
First, make the recognizer work, with the predefined templates. You can write code for Canvas (or any other method you wish to implement). Then you
can add event listeners for mouseDown, mouseMove and mouseUp, and record the points drawn by the user. These are the points that you will send to the $1
recognizer to recognize. Now originally, the $1 recognizer will not have your gestures. So, you can implement the above code, draw a gesture and
print the points recognized by your code through the event listeners. Then, you can add the points in the $1 recognizer to the .js file,
to store the gesture.




look at the canvas element, its own mouseUp, mouseDown, mouseMove events, in-line javascript functions and dollar.js (in this order, you should have a fair understanding of what's going on around mouse events).


TEMPLATES

The dollar recognizer takes an array of points, and returns with the recognized result. This result includes the name of the recognized template, and a confidence score.

As you can see from the dollar.js file linked from the assignment and the dollar website (http://depts.washington.edu/aimgroup/proj/dollar/dollar.js), a template is just an array of points. These points are ordered samples from a unistroke gesture. For example, you could define a straight line with an array containing (0,0), (1,0), (2,0)....(30,0) . In addition, the starting point of the gesture doesn't matter, just the relative offsets between points. So, (30,50),(40,60),(50,70) behaves the same as (0,0),(10,10),(20,20). In fact, the recognizer is scale-invariant and rotation-invariant, too (which you can verify by examining the code).

Also, wrt the number of samples in a template, recall from class that the $1 gesture recognizer resamples every template and every gesture to be recognized, so that they have the same number of points. So, that makes it possible for a gesture such as the zigzag in dollar.js to be defined with so few points. For example, the five lines of the zigzag are defined by exactly six points.



NEW TEMPLATES


You can manually define your own templates in your IDE editor. For simple gestures you define, this can be done easily.

Or, you can put a breakpoint (e.g., with Firebug) in http://depts.washington.edu/aimgroup/proj/dollar/, on the javascript function where the points for a new gesture are put into the recognizer to be processed. This way, you can get the array of points for any gesture you like.

Or, you can write a very simple webpage / script that will allow you to collect the points in a gesture, and print collected gestures. Again, remember that these gestures are scale, rotation and translate invariant so the size, rotation and the starting point of these points does not matter, What matters is the relative positions of points with respect to each other.


DETAILED GESTURES


Since your code processes all the mouse events, you can record the starting point or full path of a gesture (e.g., to determine  the image in which a gesture started or all the images through which it passes). So, even though the $1 recognizer simply tells you which template was matched, you can further differentiate the images to which you'd like to apply the gesture.

Similarly, you can determine a vector (e.g., from the gesture's first point to its last point) and use that in your code to make a left-to-right gesture behave differently from a right-to-left gesture, even if they match the same template.

Do think about other ways you might parameterize an operation, based on the points in the user's original gesture.